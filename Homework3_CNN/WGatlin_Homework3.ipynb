{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "xMdKtU-XPzLn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bk432Qf32C0S"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import mnist, fashion_mnist\n",
        "import keras as kb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "iukQRqTqPtdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d kylegraupe/skin-cancer-binary-classification-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhNOESix2F-g",
        "outputId": "dc6f6f98-837d-4cac-bff7-3515a6851335"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/kylegraupe/skin-cancer-binary-classification-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading skin-cancer-binary-classification-dataset.zip to /content\n",
            " 22% 5.00M/22.5M [00:00<00:00, 39.6MB/s]\n",
            "100% 22.5M/22.5M [00:00<00:00, 110MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq /content/skin-cancer-binary-classification-dataset.zip"
      ],
      "metadata": {
        "id": "HqmPhcltJn0y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Directory formatting\n"
      ],
      "metadata": {
        "id": "d_h29XtzJlRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "cancer_train_dir = \"/content/Skin_Data/Cancer/Training\"\n",
        "cancer_test_dir = \"/content/Skin_Data/Cancer/Testing\"\n",
        "noncancer_train_dir = \"/content/Skin_Data/Non_Cancer/Training\"\n",
        "noncancer_test_dir = \"/content/Skin_Data/Non_Cancer/Testing\"\n",
        "\n",
        "new_cancer_train_dir = \"/content/Skin_Data/Training/Cancerous\"\n",
        "new_cancer_test_dir = \"/content/Skin_Data/Testing/Cancerous\"\n",
        "new_noncancer_train_dir = \"/content/Skin_Data/Training/Non-Cancerous\"\n",
        "new_noncancer_test_dir = \"/content/Skin_Data/Testing/Non-Cancerous\"\n",
        "\n",
        "os.makedirs(new_cancer_train_dir, exist_ok=True)\n",
        "os.makedirs(new_cancer_test_dir, exist_ok=True)\n",
        "os.makedirs(new_noncancer_train_dir, exist_ok=True)\n",
        "os.makedirs(new_noncancer_test_dir, exist_ok=True)\n",
        "\n",
        "for file_name in os.listdir(cancer_train_dir):\n",
        "  shutil.move(os.path.join(cancer_train_dir, file_name), new_cancer_train_dir)\n",
        "\n",
        "for file_name in os.listdir(cancer_test_dir):\n",
        "  shutil.move(os.path.join(cancer_test_dir, file_name), new_cancer_test_dir)\n",
        "\n",
        "for file_name in os.listdir(noncancer_train_dir):\n",
        "  shutil.move(os.path.join(noncancer_train_dir, file_name), new_noncancer_train_dir)\n",
        "\n",
        "for file_name in os.listdir(noncancer_test_dir):\n",
        "  shutil.move(os.path.join(noncancer_test_dir, file_name), new_noncancer_test_dir)\n"
      ],
      "metadata": {
        "id": "kv6MhDdEJOQN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/Skin_Data/Training\"\n",
        "test_dir = \"/content/Skin_Data/Testing\""
      ],
      "metadata": {
        "id": "f9XhyMWnO4nn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading into Keras"
      ],
      "metadata": {
        "id": "rw98r1KyP_0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "img_height = 170\n",
        "img_width = 170\n",
        "train_ds = kb.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_ds = kb.utils.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3ZM2-24O9lQ",
        "outputId": "99f7355a-406d-40c1-a395-234c10daa4f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 files belonging to 2 classes.\n",
            "Found 204 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model\n"
      ],
      "metadata": {
        "id": "fyRI_m1LQMXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = kb.Sequential()\n",
        "\n",
        "model.add(kb.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(kb.layers.BatchNormalization())\n",
        "model.add(kb.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(kb.layers.Conv2D(16, (3, 3), activation='relu', kernel_regularizer=kb.regularizers.l2(0.001)))\n",
        "model.add(kb.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=kb.regularizers.l2(0.001)))\n",
        "model.add(kb.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(kb.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=kb.regularizers.l2(0.001)))\n",
        "model.add(kb.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=kb.regularizers.l2(0.001)))\n",
        "model.add(kb.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(kb.layers.Flatten())\n",
        "model.add(kb.layers.Dense(64, activation='relu'))\n",
        "model.add(kb.layers.Dropout(0.5))\n",
        "model.add(kb.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "lr_schedule = kb.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.001, decay_steps=35, decay_rate=0.8)\n",
        "model.compile(optimizer=kb.optimizers.Adam(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=['accuracy', kb.metrics.Precision(), kb.metrics.Recall()])\n",
        "\n",
        "early_stopping = kb.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "#lr_scheduler = kb.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "history = model.fit(train_ds, epochs=12, validation_data=test_ds, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liRzNzkgQL0a",
        "outputId": "244d2259-8b58-4c0a-8938-6e89fd56a985"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.5197 - loss: 1.3204 - precision_2: 0.5443 - recall_2: 0.4715 - val_accuracy: 0.7941 - val_loss: 0.7042 - val_precision_2: 0.7941 - val_recall_2: 1.0000\n",
            "Epoch 2/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6077 - loss: 0.8706 - precision_2: 0.5738 - recall_2: 0.7543 - val_accuracy: 0.2549 - val_loss: 0.9488 - val_precision_2: 1.0000 - val_recall_2: 0.0617\n",
            "Epoch 3/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7077 - loss: 0.6917 - precision_2: 0.7679 - recall_2: 0.5381 - val_accuracy: 0.7892 - val_loss: 0.6468 - val_precision_2: 0.8148 - val_recall_2: 0.9506\n",
            "Epoch 4/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7812 - loss: 0.6718 - precision_2: 0.7270 - recall_2: 0.9315 - val_accuracy: 0.2549 - val_loss: 1.2503 - val_precision_2: 1.0000 - val_recall_2: 0.0617\n",
            "Epoch 5/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7346 - loss: 0.6258 - precision_2: 0.7204 - recall_2: 0.7031 - val_accuracy: 0.7892 - val_loss: 0.6023 - val_precision_2: 0.8115 - val_recall_2: 0.9568\n",
            "Epoch 6/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7542 - loss: 0.6272 - precision_2: 0.6832 - recall_2: 1.0000 - val_accuracy: 0.7794 - val_loss: 0.6465 - val_precision_2: 0.9034 - val_recall_2: 0.8086\n",
            "Epoch 7/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8952 - loss: 0.5248 - precision_2: 0.8840 - recall_2: 0.9273 - val_accuracy: 0.7892 - val_loss: 0.5920 - val_precision_2: 0.8940 - val_recall_2: 0.8333\n",
            "Epoch 8/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9020 - loss: 0.4474 - precision_2: 0.8636 - recall_2: 0.9370 - val_accuracy: 0.8039 - val_loss: 0.7543 - val_precision_2: 0.8280 - val_recall_2: 0.9506\n",
            "Epoch 9/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8470 - loss: 0.4665 - precision_2: 0.7895 - recall_2: 0.9071 - val_accuracy: 0.7990 - val_loss: 0.6311 - val_precision_2: 0.8854 - val_recall_2: 0.8580\n",
            "Epoch 10/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8808 - loss: 0.4542 - precision_2: 0.8406 - recall_2: 0.9559 - val_accuracy: 0.7451 - val_loss: 0.7130 - val_precision_2: 0.9741 - val_recall_2: 0.6975\n",
            "Epoch 11/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8931 - loss: 0.4022 - precision_2: 0.9289 - recall_2: 0.8688 - val_accuracy: 0.7157 - val_loss: 0.7290 - val_precision_2: 0.9906 - val_recall_2: 0.6481\n",
            "Epoch 12/12\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8900 - loss: 0.4501 - precision_2: 0.8584 - recall_2: 0.9380 - val_accuracy: 0.8186 - val_loss: 0.5011 - val_precision_2: 0.9371 - val_recall_2: 0.8272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Model"
      ],
      "metadata": {
        "id": "ADPEoFbCQDKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0"
      ],
      "metadata": {
        "id": "01H_9hnX1t7w"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "model = kb.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(kb.layers.Flatten())\n",
        "model.add(kb.layers.Dense(128, activation='relu'))\n",
        "model.add(kb.layers.Dropout(0.3))\n",
        "model.add(kb.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=kb.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, epochs=5, validation_data=test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PZYXzF8TH9p",
        "outputId": "e7b5df9e-ef57-45fe-baeb-68059a119c21"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 5s/step - accuracy: 0.6834 - loss: 1.1269 - val_accuracy: 0.7941 - val_loss: 2.0638\n",
            "Epoch 2/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.7847 - loss: 1.3909 - val_accuracy: 0.3971 - val_loss: 4.4221\n",
            "Epoch 3/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.9044 - loss: 0.4297 - val_accuracy: 0.8529 - val_loss: 0.7451\n",
            "Epoch 4/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4s/step - accuracy: 0.9874 - loss: 0.0306 - val_accuracy: 0.7941 - val_loss: 4.4006\n",
            "Epoch 5/5\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - accuracy: 0.9082 - loss: 0.3762 - val_accuracy: 0.8039 - val_loss: 2.8992\n"
          ]
        }
      ]
    }
  ]
}